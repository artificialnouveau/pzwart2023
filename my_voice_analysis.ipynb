{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bae11a2-a5f2-4aad-bf43-88fbc24fee8f",
   "metadata": {},
   "source": [
    "### Import libraries and create custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac42ba2e-625f-4030-8a87-3212e33f5da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import json\n",
    "import os\n",
    "from IPython.display import Audio, display, HTML\n",
    "from pydub import AudioSegment\n",
    "from pytube import YouTube\n",
    "from moviepy.editor import *\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import random\n",
    "from simple_diarizer.diarizer import Diarizer\n",
    "from simple_diarizer.utils import (check_wav_16khz_mono, convert_wavfile,\n",
    "                                   waveplot, combined_waveplot, waveplot_perspeaker)\n",
    "import tempfile\n",
    "from pprint import pprint\n",
    "import soundfile as sf\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "\n",
    "def split_into_sentences(segments):\n",
    "    sentences = []\n",
    "    current_sentence = []\n",
    "    for segment in segments:\n",
    "        word, start, end = segment['text'], segment['start'], segment['end']\n",
    "        current_sentence.append((word, start, end))\n",
    "        if word.endswith('.'):\n",
    "            sentences.append(current_sentence)\n",
    "            current_sentence = []\n",
    "    if current_sentence:\n",
    "        sentences.append(current_sentence)\n",
    "    return sentences\n",
    "\n",
    "def segment_audio(filename, sentences):\n",
    "    audio = AudioSegment.from_file(filename)\n",
    "    segments = []\n",
    "    for sentence in sentences:\n",
    "        start = int(sentence[0][1] * 1000)  # Convert to milliseconds\n",
    "        end = int(sentence[-1][2] * 1000)\n",
    "        segment = audio[start:end]\n",
    "        segments.append(segment)\n",
    "    return segments\n",
    "\n",
    "def save_audio_segment(segment, filename):\n",
    "    segment.export(filename, format=\"wav\")\n",
    "\n",
    "def analyze_audio(filename, analyze_by_sentence=False):\n",
    "    mysp = __import__(\"my-voice-analysis\")\n",
    "\n",
    "    model = whisper.load_model(\"base\")\n",
    "    result = model.transcribe(filename)\n",
    "    text = result[\"text\"]\n",
    "    print('Transcribed text: ', text)\n",
    "    print('')\n",
    "\n",
    "    file = os.path.basename(filename).replace('.wav', '')\n",
    "    directory = os.path.dirname(filename)\n",
    "\n",
    "    if analyze_by_sentence:\n",
    "        sentences = split_into_sentences(result[\"segments\"])\n",
    "        audio_segments = segment_audio(filename, sentences)\n",
    "\n",
    "        analyses = []\n",
    "\n",
    "        for i, segment in enumerate(audio_segments):\n",
    "            temp_filename = os.path.join(directory, f\"temp_segment_{i}.wav\")\n",
    "            save_audio_segment(segment, temp_filename)\n",
    "\n",
    "            try:\n",
    "                temp_filename_ = os.path.basename(temp_filename).replace('.wav', '')\n",
    "                gender, emotion = mysp.myspgend(temp_filename_, directory)\n",
    "                dataset, *analysis_results = mysp.mysptotal(temp_filename_, directory)\n",
    "            except:\n",
    "                gender = emotion = \"Unknown\"\n",
    "                analysis_results = [\"Unknown\"] * 13\n",
    "\n",
    "            analyses.append({\n",
    "                \"sentence\": ' '.join([word[0] for word in sentences[i]]),\n",
    "                \"gender\": gender,\n",
    "                \"emotion\": emotion,\n",
    "                **dict(zip([\"number_of_syllables\", \"number_of_pauses\", \"rate_of_speech\", \"articulation_rate\", \"speaking_duration\", \"original_duration\", \"balance\", \"f0_mean\", \"f0_std\", \"f0_median\", \"f0_min\", \"f0_max\", \"f0_quantile25\", \"f0_quan75\"], analysis_results))\n",
    "            })\n",
    "\n",
    "            os.remove(temp_filename)\n",
    "    else:\n",
    "        try:\n",
    "            gender, emotion = mysp.myspgend(file, directory)\n",
    "            dataset, *analysis_results = mysp.mysptotal(file, directory)\n",
    "        except:\n",
    "            gender = emotion = \"Unknown\"\n",
    "            analysis_results = [\"Unknown\"] * 13\n",
    "\n",
    "        analyses = [{\n",
    "            \"filename\": filename,\n",
    "            \"text\": text,\n",
    "            \"gender\": gender,\n",
    "            \"emotion\": emotion,\n",
    "            **dict(zip([\"number_of_syllables\", \"number_of_pauses\", \"rate_of_speech\", \"articulation_rate\", \"speaking_duration\", \"original_duration\", \"balance\", \"f0_mean\", \"f0_std\", \"f0_median\", \"f0_min\", \"f0_max\", \"f0_quantile25\", \"f0_quan75\"], analysis_results))\n",
    "        }]\n",
    "\n",
    "    return analyses\n",
    "\n",
    "def sanitize_filename(filename):\n",
    "    \"\"\"Remove spaces and special characters from the filename.\"\"\"\n",
    "    filename = re.sub(r'[^a-zA-Z0-9\\-_\\.]', '', filename.replace(\" \", \"_\"))\n",
    "    return filename\n",
    "\n",
    "def download_youtube_audio(url, output_path=\"downloaded_audio\"):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    # Download YouTube video\n",
    "    yt = YouTube(url)\n",
    "    video_stream = yt.streams.filter(only_audio=True).first()\n",
    "    audio_file = video_stream.download(output_path=output_path)\n",
    "\n",
    "    # Sanitize filename\n",
    "    sanitized_filename = sanitize_filename(yt.title) + '.wav'\n",
    "    wav_filepath = os.path.join(output_path, sanitized_filename)\n",
    "\n",
    "    audio_clip = AudioFileClip(audio_file)\n",
    "    audio_clip.write_audiofile(wav_filepath, fps=44100, nbytes=2, codec='pcm_s16le')\n",
    "\n",
    "    # Remove the original download (if it's not a wav file)\n",
    "    if not audio_file.endswith('.wav'):\n",
    "        os.remove(audio_file)\n",
    "\n",
    "    print(f\"Audio downloaded and converted to WAV: {wav_filepath}\")\n",
    "    return wav_filepath\n",
    "\n",
    "\n",
    "def shorten_sentence(sentence):\n",
    "    words = sentence.split()\n",
    "    if len(words) > 20:\n",
    "        return ' '.join(words[:5]) + ' ... ' + ' '.join(words[-5:])\n",
    "    return sentence\n",
    "\n",
    "    \n",
    "def freq_plot(analysis_results):\n",
    "    data = analysis_results\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Convert columns to numeric as needed\n",
    "    numeric_cols = ['f0_mean', 'f0_std', 'f0_median', 'f0_min', 'f0_max', 'f0_quantile25', 'f0_quan75']\n",
    "    df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    # Use color to represent emotion - can map each emotion to a color\n",
    "    # Ensure emotions have random colors\n",
    "    unique_emotions = df['emotion'].unique()\n",
    "    emotion_colors = {emotion: \"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for emotion in unique_emotions}\n",
    "    \n",
    "    # Plotting only f0_median with quantiles as confidence\n",
    "    plt.figure(figsize=(15, max(6, len(df) / 2)))  # Adjust figure size as needed\n",
    "    \n",
    "    # Plotting each point and its confidence interval\n",
    "    for i, row in df.iterrows():\n",
    "        plt.plot(row['f0_median'], i, 'o', color=emotion_colors[row['emotion']])\n",
    "        plt.hlines(i, row['f0_quantile25'], row['f0_quan75'], color=emotion_colors[row['emotion']], alpha=0.3)\n",
    "\n",
    "    # Shorten sentences if they are too long\n",
    "    df['sentence_short'] = df['sentence'].copy()\n",
    "    df['sentence_short'] = df['sentence_short'].apply(shorten_sentence)\n",
    "    \n",
    "    plt.yticks(ticks=df.index, labels=df['sentence_short'])\n",
    "    plt.title(\"Median Fundamental Frequency (F0) with Confidence Intervals for Each Sentence\")\n",
    "    plt.ylabel(\"Sentences\")\n",
    "    plt.xlabel(\"Frequency (Hz)\")\n",
    "    \n",
    "    # Create a legend for the emotions\n",
    "    legend_elements = [Line2D([0], [0], color=color, lw=4, label=emotion) for emotion, color in emotion_colors.items()]\n",
    "    plt.legend(handles=legend_elements, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def heat_plot(analysis_results):\n",
    "    data = analysis_results\n",
    "    df = pd.DataFrame(data)\n",
    "    # Convert columns to numeric as needed\n",
    "    numeric_cols = ['number_of_syllables', 'number_of_pauses', 'rate_of_speech', \n",
    "                    'articulation_rate', 'speaking_duration', 'f0_mean', 'f0_std', \n",
    "                    'f0_median', 'f0_min', 'f0_max', 'f0_quantile25', 'f0_quan75']\n",
    "    df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "    df['sentence_short'] = df['sentence'].copy()\n",
    "    df['sentence_short'] = df['sentence_short'].apply(shorten_sentence)\n",
    "\n",
    "    # Ensure all columns are numeric for the heatmap\n",
    "    heatmap_data = df[numeric_cols]\n",
    "    \n",
    "    # Drop any rows with NaN values (if necessary)\n",
    "    heatmap_data = heatmap_data.dropna()\n",
    "\n",
    "    # Create the heatmap\n",
    "    plt.figure(figsize=(len(heatmap_data.columns), 15))  # Adjust figure size as needed\n",
    "    sns.heatmap(heatmap_data, cmap='coolwarm', annot=True, fmt='g', yticklabels=df['sentence_short'])  # 'g' format to avoid scientific notation\n",
    "    plt.title(\"Heatmap of Fundamental Frequencies and Speech Features\")\n",
    "    plt.ylabel(\"Sentences\")\n",
    "    plt.xlabel(\"Features\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dcca00-0944-4718-b6aa-b38a64624bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pytube import YouTube\n",
    "from moviepy.editor import AudioFileClip\n",
    "\n",
    "def sanitize_filename(filename):\n",
    "    # Add a simple function to sanitize filenames\n",
    "    return \"\".join(c for c in filename if c.isalnum() or c in [' ', '_', '-']).rstrip()\n",
    "\n",
    "def download_youtube_content(url, download_type=\"audio\", output_path=\"downloads\"):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    # Download YouTube content\n",
    "    yt = YouTube(url)\n",
    "\n",
    "    if download_type == \"audio\":\n",
    "        # Download only audio\n",
    "        video_stream = yt.streams.filter(only_audio=True).first()\n",
    "        audio_file = video_stream.download(output_path=output_path)\n",
    "\n",
    "        # Convert to WAV (if necessary)\n",
    "        sanitized_filename = sanitize_filename(yt.title) + '.wav'\n",
    "        wav_filepath = os.path.join(output_path, sanitized_filename)\n",
    "\n",
    "        audio_clip = AudioFileClip(audio_file)\n",
    "        audio_clip.write_audiofile(wav_filepath, fps=44100, nbytes=2, codec='pcm_s16le')\n",
    "\n",
    "        # Remove the original download (if it's not a wav file)\n",
    "        if not audio_file.endswith('.wav'):\n",
    "            os.remove(audio_file)\n",
    "\n",
    "        print(f\"Audio downloaded and converted to WAV: {wav_filepath}\")\n",
    "        return wav_filepath\n",
    "\n",
    "    elif download_type == \"video\":\n",
    "        # Download video with audio\n",
    "        video_stream = yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first()\n",
    "        video_file = video_stream.download(output_path=output_path)\n",
    "        sanitized_filename = sanitize_filename(yt.title) + '.mp4'\n",
    "        sanitized_filepath = os.path.join(output_path, sanitized_filename)\n",
    "        os.rename(video_file, sanitized_filepath)\n",
    "\n",
    "        print(f\"Video downloaded: {sanitized_filepath}\")\n",
    "        return sanitized_filepath\n",
    "\n",
    "# Example usage\n",
    "download_youtube_content(\"https://www.youtube.com/watch?v=rKX4oOXQ2j0\", download_type=\"video\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcd479c-c07d-4b2b-8af2-426d3057a0ea",
   "metadata": {},
   "source": [
    "## Prepare your audio\n",
    "\n",
    "You can use your own audio. However, your audio files must be in *.wav format, recorded at 44 kHz sample frame and 16 bits of resolution.\n",
    "\n",
    "You also have the option to download the audio from youtube. This can either be of someone speaking or someone singing. \n",
    "\n",
    "Please select audio that is less than 10 mins long. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442ca00e-1c3e-41af-82ef-2d6b299e889d",
   "metadata": {},
   "source": [
    "### Download youtube audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8dd5ac-219e-4daf-8fa9-495d7b0f7b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "def trim_wav_file(input_file_path, start_time_s, end_time_s=None):\n",
    "    \"\"\"\n",
    "    Trims a .wav file from start_time_s and optionally to end_time_s, then saves it as a new file.\n",
    "\n",
    "    Args:\n",
    "    input_file_path (str): Path to the input .wav file.\n",
    "    start_time_s (int): Start time in seconds to begin trimming.\n",
    "    end_time_s (int, optional): End time in seconds to stop trimming. If None, the audio is trimmed only from the start.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_wav(input_file_path)\n",
    "\n",
    "    # Determine the end time for trimming\n",
    "    if end_time_s is not None:\n",
    "        trimmed_audio = audio[start_time_s * 1000:end_time_s * 1000]\n",
    "        end_time_label = f\"_to_{end_time_s}s\"\n",
    "    else:\n",
    "        trimmed_audio = audio[start_time_s * 1000:]\n",
    "        end_time_label = \"\"\n",
    "\n",
    "    # Create the new file name with timestamps\n",
    "    file_name, file_extension = os.path.splitext(input_file_path)\n",
    "    new_file_name = f\"{file_name}_{start_time_s}s{end_time_label}{file_extension}\"\n",
    "\n",
    "    # Export the trimmed audio\n",
    "    trimmed_audio.export(new_file_name, format=\"wav\")\n",
    "\n",
    "    print(f\"Trimmed audio saved to {new_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4530327-0f69-4d6b-b991-7a142e1ae021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace or add your YouTube URLs\n",
    "youtube_urls = [\"https://youtu.be/InR69mIZMzA\", \"https://www.youtube.com/watch?v=uAPUkgeiFVY\", \"https://www.youtube.com/watch?v=Ez-L0qW9iGQ\"]\n",
    "for url in youtube_urls:\n",
    "    download_youtube_audio(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cfbecc-2ffb-405a-a11e-76df5d1fbe3a",
   "metadata": {},
   "source": [
    "### Separate vocals from instruments\n",
    "\n",
    "If you are using audio from a song then you can separate the vocals from the instruments using spleeter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbb4f94-1c1f-4057-a41d-bf8bde0131d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = './downloaded_audio/'\n",
    "input_audio = './downloaded_audio/The_Heart_Part_5.wav'\n",
    "!spleeter separate -o {output_folder} {input_audio}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c265189-52fa-4300-a160-410882ea16f8",
   "metadata": {},
   "source": [
    "### You can trim the wav file here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f731b41-8b3c-4c10-8102-3c8f885cc2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trim_wav_file('./downloaded_audio/The_Heart_Part_5.wav', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30548777-a5dc-41de-8a0b-4aaf5983f088",
   "metadata": {},
   "source": [
    "### Playback audio\n",
    "If the audio file is too long, then this audio plug-in will not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3647ced3-9741-468f-842f-b804779ed23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are using backward slash, then add r in front of the filepath. If you are using forward slash, then no r necessary\n",
    "file_path = r\".\\downloaded_audio\\Justin_Trudeau_says_he_does_not_remember_how_many_times_he_wore_blackface.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b45210-aec3-4ef5-8862-cd44d3aeec24",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(filename=file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2329f7c0-ab56-4a6b-ba6b-af9a799ef2c8",
   "metadata": {},
   "source": [
    "## Analysis Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961ea929-db68-48fc-96b9-7030f6ccf7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_by_sentence = True  # Set to False to analyze the whole audio\n",
    "analysis_results = analyze_audio(file_path, analyze_by_sentence)\n",
    "analysis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933d9932-d150-44d3-afce-f6d9a6a36378",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_plot(analysis_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f35708-8e7c-4a24-a851-6e51aac06c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_plot(analysis_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16691f93-fefd-4777-bd39-9deb5cc26332",
   "metadata": {},
   "outputs": [],
   "source": [
    "diarization = Diarizer(embed_model='xvec', cluster_method='sc')\n",
    "segments = diarization.diarize(file_path, num_speakers=2)\n",
    "segments   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7804443c-ad1b-492a-abba-95b0a1790996",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal, fs = sf.read(file_path)\n",
    "combined_waveplot(signal, fs, segments)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbfdb21-cb00-4930-b87c-f817ca96bf46",
   "metadata": {},
   "source": [
    "### Speaker Similiarity\n",
    "\n",
    "#### Enroll stage\n",
    "\n",
    "The enroll workflow requires two parameters, one being a unique numeric id that must be 9 characters long and a path to a wav or flac file of the users voice. Below is the required syntax and format for the this stage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f929b83-380e-4a10-a576-e6cb18b69e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m speaker_verification enroll --id 123456789 --audio-path C:/Users/ahnji/OneDrive/Documents/Prototypes/PietZwart/downloaded_audio/Prime_Minister_Trudeaus_message_on_Remembrance_Day.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e5617b-28e4-40ad-88a9-56d07b0f20fc",
   "metadata": {},
   "source": [
    "### Validate stage\n",
    "\n",
    "The validate workflow retrives a user enrollment based on the given id parameter given and then uses the --audio-path input to accept an audio file as speaker input to verify against the given user enrollment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202209f3-e6e0-4929-87ab-c0dc43d0dec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m speaker_verification validate --id 123456789 --audio-path C:/Users/ahnji/OneDrive/Documents/Prototypes/PietZwart/downloaded_audio/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
